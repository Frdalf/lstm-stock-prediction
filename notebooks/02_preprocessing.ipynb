{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 02 - Data Preprocessing\n",
                "\n",
                "Notebook ini berisi preprocessing data untuk LSTM model:\n",
                "\n",
                "## Steps:\n",
                "1. Load data yang sudah di-download\n",
                "2. Normalisasi menggunakan MinMaxScaler\n",
                "3. Create sequences (60 hari untuk prediksi hari ke-61)\n",
                "4. Split train/test dengan ratio 80:20"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import sys\n",
                "sys.path.append('..')\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "from src.data_loader import DataLoader\n",
                "from src.preprocessor import StockPreprocessor, MultiFeaturePreprocessor\n",
                "from src.visualizer import StockVisualizer\n",
                "\n",
                "# Set random seed for reproducibility\n",
                "np.random.seed(42)\n",
                "\n",
                "print(\"Libraries imported successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize data loader\n",
                "loader = DataLoader(data_dir='../data/raw')\n",
                "\n",
                "# Load previously downloaded data\n",
                "TICKER = \"AAPL\"  # Same ticker as exploration notebook\n",
                "\n",
                "try:\n",
                "    data = loader.load_data(TICKER)\n",
                "except FileNotFoundError:\n",
                "    print(\"Data not found. Downloading...\")\n",
                "    data = loader.download_stock_data(TICKER, period=\"5y\")\n",
                "\n",
                "print(f\"\\nData shape: {data.shape}\")\n",
                "data.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Quick data check\n",
                "print(f\"Date range: {data['Date'].min()} to {data['Date'].max()}\")\n",
                "print(f\"Missing values: {data.isnull().sum().sum()}\")\n",
                "\n",
                "# Close price statistics\n",
                "print(f\"\\nClose Price Statistics:\")\n",
                "print(data['Close'].describe())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Preprocessing Parameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define preprocessing parameters\n",
                "SEQUENCE_LENGTH = 60  # 60 days lookback\n",
                "TRAIN_RATIO = 0.8     # 80% for training\n",
                "TARGET_COLUMN = 'Close'\n",
                "\n",
                "print(f\"Sequence Length: {SEQUENCE_LENGTH} days\")\n",
                "print(f\"Train/Test Split: {TRAIN_RATIO*100:.0f}/{(1-TRAIN_RATIO)*100:.0f}\")\n",
                "print(f\"Target Column: {TARGET_COLUMN}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Basic Preprocessing (Single Feature - Close Price)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize preprocessor\n",
                "preprocessor = StockPreprocessor(\n",
                "    sequence_length=SEQUENCE_LENGTH,\n",
                "    feature_columns=[TARGET_COLUMN]\n",
                ")\n",
                "\n",
                "# Prepare data\n",
                "X_train, y_train, X_test, y_test = preprocessor.prepare_data(\n",
                "    data,\n",
                "    target_column=TARGET_COLUMN,\n",
                "    train_ratio=TRAIN_RATIO\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display shapes\n",
                "print(f\"\\n=== Data Shapes ===\")\n",
                "print(f\"X_train: {X_train.shape} - (samples, timesteps, features)\")\n",
                "print(f\"y_train: {y_train.shape}\")\n",
                "print(f\"X_test: {X_test.shape}\")\n",
                "print(f\"y_test: {y_test.shape}\")\n",
                "\n",
                "print(f\"\\nTotal samples: {len(X_train) + len(X_test)}\")\n",
                "print(f\"Training samples: {len(X_train)} ({len(X_train)/(len(X_train)+len(X_test))*100:.1f}%)\")\n",
                "print(f\"Testing samples: {len(X_test)} ({len(X_test)/(len(X_train)+len(X_test))*100:.1f}%)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize sample sequence\n",
                "sample_idx = 100\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Sample input sequence\n",
                "axes[0].plot(X_train[sample_idx, :, 0])\n",
                "axes[0].set_title(f'Sample Input Sequence (Normalized) - Index {sample_idx}')\n",
                "axes[0].set_xlabel('Time Steps')\n",
                "axes[0].set_ylabel('Normalized Value')\n",
                "axes[0].grid(True, alpha=0.3)\n",
                "\n",
                "# Target distribution\n",
                "axes[1].hist(y_train, bins=50, alpha=0.7, edgecolor='white', label='Train')\n",
                "axes[1].hist(y_test, bins=50, alpha=0.7, edgecolor='white', label='Test')\n",
                "axes[1].set_title('Target Values Distribution (Normalized)')\n",
                "axes[1].set_xlabel('Normalized Close Price')\n",
                "axes[1].set_ylabel('Frequency')\n",
                "axes[1].legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Verify Normalization (MinMax Scaling)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check normalized values are in [0, 1] range\n",
                "print(\"=== Normalization Verification ===\")\n",
                "print(f\"\\nX_train:\")\n",
                "print(f\"  Min: {X_train.min():.6f}\")\n",
                "print(f\"  Max: {X_train.max():.6f}\")\n",
                "\n",
                "print(f\"\\ny_train:\")\n",
                "print(f\"  Min: {y_train.min():.6f}\")\n",
                "print(f\"  Max: {y_train.max():.6f}\")\n",
                "\n",
                "print(f\"\\ny_test:\")\n",
                "print(f\"  Min: {y_test.min():.6f}\")\n",
                "print(f\"  Max: {y_test.max():.6f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test inverse transform\n",
                "sample_predictions = y_test[:5].reshape(-1, 1)\n",
                "original_scale = preprocessor.inverse_transform_predictions(sample_predictions)\n",
                "\n",
                "print(\"\\n=== Inverse Transform Test ===\")\n",
                "print(\"Normalized -> Original Scale:\")\n",
                "for norm, orig in zip(sample_predictions.flatten(), original_scale.flatten()):\n",
                "    print(f\"  {norm:.4f} -> ${orig:.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Multi-Feature Preprocessing (Optional)\n",
                "\n",
                "Menggunakan multiple features seperti Open, High, Low, Close, Volume dan technical indicators."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Multi-feature preprocessing\n",
                "multi_preprocessor = MultiFeaturePreprocessor(\n",
                "    sequence_length=SEQUENCE_LENGTH,\n",
                "    feature_columns=['Close', 'Open', 'High', 'Low', 'Volume']\n",
                ")\n",
                "\n",
                "# Add technical indicators\n",
                "data_with_indicators = multi_preprocessor.add_technical_indicators(data)\n",
                "\n",
                "print(\"\\nFeatures available:\")\n",
                "print(data_with_indicators.columns.tolist())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preview data with indicators\n",
                "data_with_indicators.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Optional: Use multi-feature for training\n",
                "USE_MULTI_FEATURE = False  # Set to True to use multiple features\n",
                "\n",
                "if USE_MULTI_FEATURE:\n",
                "    # Select features to use\n",
                "    selected_features = ['Close', 'Volume', 'MA_7', 'MA_21', 'RSI']\n",
                "    \n",
                "    multi_preprocessor_full = MultiFeaturePreprocessor(\n",
                "        sequence_length=SEQUENCE_LENGTH,\n",
                "        feature_columns=selected_features\n",
                "    )\n",
                "    \n",
                "    X_train_multi, y_train_multi, X_test_multi, y_test_multi = multi_preprocessor_full.prepare_data(\n",
                "        data_with_indicators,\n",
                "        target_column='Close',\n",
                "        train_ratio=TRAIN_RATIO\n",
                "    )\n",
                "    \n",
                "    print(f\"\\nMulti-feature shapes:\")\n",
                "    print(f\"X_train: {X_train_multi.shape}\")\n",
                "    print(f\"X_test: {X_test_multi.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Visualize Train/Test Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate split point in original data\n",
                "split_point = int(len(data) * TRAIN_RATIO)\n",
                "\n",
                "# Account for sequence length\n",
                "train_end_idx = split_point + SEQUENCE_LENGTH\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(14, 7))\n",
                "\n",
                "# Plot training data\n",
                "ax.plot(data['Date'][:train_end_idx], data['Close'][:train_end_idx], \n",
                "        color='#1B998B', label='Training Data', linewidth=1.5)\n",
                "\n",
                "# Plot test data\n",
                "ax.plot(data['Date'][train_end_idx:], data['Close'][train_end_idx:], \n",
                "        color='#F46036', label='Test Data', linewidth=1.5)\n",
                "\n",
                "# Add vertical line for split\n",
                "ax.axvline(x=data['Date'].iloc[train_end_idx], color='gray', \n",
                "           linestyle='--', linewidth=2, label='Train/Test Split')\n",
                "\n",
                "ax.set_title(f'{TICKER} Train/Test Split Visualization', fontsize=14, fontweight='bold')\n",
                "ax.set_xlabel('Date')\n",
                "ax.set_ylabel('Close Price (USD)')\n",
                "ax.legend(loc='upper left')\n",
                "ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nSplit Date: {data['Date'].iloc[train_end_idx].strftime('%Y-%m-%d')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Save Preprocessed Data & Scaler"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save scaler for later use\n",
                "preprocessor.save_scaler(filepath='../models/scaler.pkl')\n",
                "\n",
                "# Save preprocessed data as numpy arrays\n",
                "import os\n",
                "os.makedirs('../data/processed', exist_ok=True)\n",
                "\n",
                "np.save('../data/processed/X_train.npy', X_train)\n",
                "np.save('../data/processed/y_train.npy', y_train)\n",
                "np.save('../data/processed/X_test.npy', X_test)\n",
                "np.save('../data/processed/y_test.npy', y_test)\n",
                "\n",
                "print(\"Preprocessed data saved to ../data/processed/\")\n",
                "print(\"Scaler saved to ../models/scaler.pkl\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Summary\n",
                "\n",
                "### Preprocessing Complete!\n",
                "\n",
                "| Parameter | Value |\n",
                "|-----------|-------|\n",
                "| Sequence Length | 60 days |\n",
                "| Train/Test Ratio | 80/20 |\n",
                "| Normalization | MinMaxScaler (0-1) |\n",
                "| Target Column | Close Price |\n",
                "\n",
                "### Files Created:\n",
                "- `data/processed/X_train.npy` - Training features\n",
                "- `data/processed/y_train.npy` - Training targets\n",
                "- `data/processed/X_test.npy` - Test features\n",
                "- `data/processed/y_test.npy` - Test targets\n",
                "- `models/scaler.pkl` - Saved scaler for inverse transform\n",
                "\n",
                "### Next Step:\n",
                "â†’ **03_model_training.ipynb** - Build and train LSTM model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"PREPROCESSING SUMMARY\")\n",
                "print(\"=\"*50)\n",
                "print(f\"Ticker: {TICKER}\")\n",
                "print(f\"Sequence Length: {SEQUENCE_LENGTH}\")\n",
                "print(f\"Features: {preprocessor.feature_columns}\")\n",
                "print(f\"X_train shape: {X_train.shape}\")\n",
                "print(f\"X_test shape: {X_test.shape}\")\n",
                "print(\"\\nReady for model training!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}